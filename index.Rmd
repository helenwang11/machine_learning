---
title: "Prediction of quality of weight lifting exercises"
author: "Yuying Wang"
date: "January 5, 2017"
output: html_document
---

Synopsis: One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). More information: http://groupware.les.inf.puc-rio.br/har#ixzz4V7DNAa2v.
In this project we train a random forest classfier using the training data and use it to predict the fashion of weight lifting in the testing data set.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,echo=FALSE,warning=FALSE,echo=FALSE}
setwd("~/Documents/datascience/MachineLearning/machine_learning_final_project")
library(parallel)
library(doParallel)
library(caret)
```

##Load the data and preprocess

First load the data and preprocess it by removing timestamp columns since those won't be used in training.
```{r load data and preprocess, cache = TRUE}
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",destfile="pml-training.csv")
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",destfile="pml-testing.csv")
read.csv("pml-training.csv",na.strings=c("","NA"))->training
# remove columns that don't have data
!is.na(training[1,])->cols
training_data = training[,cols]
# remove columns that have timestamp data, which won't be used in training
training_data = training_data[,-c(1,3,4,5,6,7)]

read.csv("pml-testing.csv",na.strings=c("","NA"))->testing
# preprocess testing data the same way as training data
testing_data = testing[,cols]
testing_data = testing_data[,-c(1,3,4,5,6,7)]
```

##Exploratory analysis

Next make some feature plots to take a look at the relationship between the variable classe and predictors. For simplicity purpose here we only look at user "carlitos". We can see that if we want to obtain the best separation of the classe variable we may want to use all the variables in the training.

```{r exploratory analysis,echo=FALSE,cache=TRUE}
training_data[training_data$user_name=="carlitos",] -> carlitos
c("roll_belt","pitch_belt","yaw_belt","total_accel_belt")->belt
featureplot<-featurePlot(x = carlitos[, belt], y = carlitos$classe, plot = "pairs",auto.key = list(columns = 3))
featureplot

c("roll_arm","pitch_arm","yaw_arm","total_accel_arm")->arm
featureplot<-featurePlot(x = carlitos[, arm], 
            y = carlitos$classe, 
            plot = "pairs",
            ## Add a key at the top
            auto.key = list(columns = 3))
featureplot

c("roll_forearm","pitch_forearm","yaw_forearm","total_accel_forearm")->forearm
featureplot<-featurePlot(x = carlitos[, forearm], 
            y = carlitos$classe, 
            plot = "pairs",
            ## Add a key at the top
            auto.key = list(columns = 3))
featureplot

c("roll_dumbbell","pitch_dumbbell","yaw_dumbbell","total_accel_dumbbell")->dumbbell
featureplot<-featurePlot(x = carlitos[, dumbbell], 
            y = carlitos$classe, 
            plot = "pairs",
            ## Add a key at the top
            auto.key = list(columns = 3))
featureplot
```

##Train the classifier
Train a random forest classifier using all the variables except "classe" as predictors. We hope that this should give us the maximum amount of accuracy. Because of the large number of predictors, in order to speed up the algorithm, I choose to use parallel processing. I choose to use 10-fold cross validation in the training process to evaluate out-of-sample error.

```{r train the model, cache = TRUE,warning=FALSE}
set.seed(33833)
cluster <- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

# here we use 10-fold cross-validation to tune the model and to estimate out-of-sample error
fitControl <- trainControl(method = "cv",
                           number = 10,
                           allowParallel = TRUE)

fit <- train(classe~.,method = "rf",data = training_data,trControl = fitControl)
stopCluster(cluster)
registerDoSEQ()
confusionMatrix.train(fit)
```

This gives us an accuracy = 99.55% (averaged across cross-validation sets).

## Prediction on the test data
Now apply it to the testing data to obtain the predictions
```{r generate prediction, cache=TRUE}
test_pred <- predict(fit,newdata=testing_data)
test_pred
```
